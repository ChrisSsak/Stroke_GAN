# -*- coding: utf-8 -*-
"""Renderer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14reuVeRd5-ms4QXAbTNpDMwUb5PWqXMl
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt

#stroke dataset
data = np.load('/content/drive/MyDrive/Yr3Project/strokedataset.npz', allow_pickle=True)

xdata=data['arr_0'] #params
ydata=data['arr_1'] #stroke

import cv2
import numpy as np



newydata=np.array([cv2.resize(stroke, dsize=(216, 216), interpolation=cv2.INTER_CUBIC)for stroke in ydata])

def normalize(l):
  a=l.astype('float32')
  a-=np.min(a)
  a/=np.max(a)
  return a

newydata=np.array([cv2.normalize(a, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U) for a in newydata])#convert to uint8
newydata.shape

newydata=np.array(newydata0)

import matplotlib.pyplot as plt
plt.imshow(newydata[15])

xtrain=xdata[:9000]#training
ytrain=newydata[:9000]


xtest=xdata[9000:]#testing
ytest=newydata[9000:]

import keras
from keras.models import Model
from keras.layers import Input, Flatten,Dense, Convolution2D, MaxPooling2D
from keras.optimizers import Adam

import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization,Reshape,Conv2DTranspose
from keras.layers import LeakyReLU

from keras.layers import Input,Lambda,UpSampling2D, BatchNormalization
def NeuralRenderer():
  x_in=Input(shape=(10,))
  x=Dense(100,activation='relu')(x_in)
  x=BatchNormalization()(x)
  #x=Dense(150,activation='relu')(x)
  #x=BatchNormalization()(x)
  x=Dense(200,activation='relu')(x)
  x=BatchNormalization()(x)
  x=Dense(512,activation='relu')(x)
  x=BatchNormalization()(x)
  x=Reshape([ 8, 8, 8])(x)
  x=keras.layers.UpSampling3D(size=(2,2,2))(x)

  x = Convolution2D(filters=32,kernel_size=3,strides=1,padding="valid",activation='relu',name="conv1")(x)# input 16
  x=BatchNormalization()(x)
  x = Convolution2D(filters=16,kernel_size=3,strides=1,padding="valid",activation='relu',name="conv2")(x)#  input 32
  x=BatchNormalization()(x)

  x=keras.layers.UpSampling2D(size=(2,2))(x)

  x = Convolution2D(filters=16,kernel_size=3,strides=1,padding="valid",activation='relu',name="conv3")(x)#   input 8
  x=BatchNormalization()(x)
  x = Convolution2D(filters=8, kernel_size=3,strides=1,padding="valid",activation='relu',name="conv4")(x)#   input 16
  x=BatchNormalization()(x)

  x=keras.layers.UpSampling2D(size=(2,2))(x)

  x = Convolution2D(filters=8, kernel_size=3,strides=1,padding="valid",activation='relu',name="conv5")(x)#   input 4
  x=BatchNormalization()(x)
  x = Convolution2D(filters=8, kernel_size=3,strides=1,padding="valid",activation='relu',name="conv6")(x) #   input 8
  x=BatchNormalization()(x)

  x=keras.layers.UpSampling2D(size=(2,2))(x)

  x = Convolution2D(filters=4, kernel_size=3,strides=1,padding="same",activation='relu',name="conv8")(x)#   input 4
  x=BatchNormalization()(x)
  x = Convolution2D(filters=1, kernel_size=1,name="conv10")(x) #   input 8
  
  x=keras.layers.UpSampling2D(size=(3,3))(x)
  

  x = tf.keras.layers.Activation(activation='sigmoid')(x)
  
  model = keras.models.Model(x_in, outputs=x, name=None)
  return model

model=NeuralRenderer()
tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)

from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint

opt=Adam(learning_rate=2e-3, beta_1=0.9, beta_2=0.999, amsgrad=False)
model.compile(optimizer=opt, loss='mae')#, metrics=['mse'])
h=model.fit(xtrain, ytrain, batch_size=64, epochs=140, validation_split=0.1, callbacks=[ReduceLROnPlateau(patience=3, verbose=1), ModelCheckpoint('/content/drive/My Drive/Yr3Project/renderer_model_normvol2.h5', save_best_only=True, verbose=1)])

from tensorflow.keras.models import load_model#prediction& evaluation
model = load_model('/content/drive/My Drive/Yr3Project/renderer_model_normvol2.h5')
predictions=model.predict(xtest)
evaluation=model.evaluate(xtest,ytest)

a=predictions[66]
plt.imshow(a[...,0])

plt.imshow(ytest[66])

